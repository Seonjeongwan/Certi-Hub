"""
Certi-Hub FastAPI ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
guide.md 2ì ˆ - Backend: FastAPI (Python)

í™•ì¥ ê¸°ëŠ¥:
  - APScheduler: ë§¤ì¼ ìƒˆë²½ 3ì‹œ ìë™ í¬ë¡¤ë§
  - CrawlLog: í¬ë¡¤ë§ ì´ë ¥ DB ê´€ë¦¬
  - seed-events.ts: DB â†’ í”„ë¡ íŠ¸ì—”ë“œ fallback ë°ì´í„° ìë™ ë™ê¸°í™”
"""

import logging
from contextlib import asynccontextmanager
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

from config import get_settings
from database import init_db
from routers import certifications, schedules
from routers.crawl import router as crawl_router

logger = logging.getLogger("main")
settings = get_settings()


# ===== Lifespan (DB ì´ˆê¸°í™” + ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘) =====

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì„œë²„ ì‹œì‘ ì‹œ DB í…Œì´ë¸” ìë™ ìƒì„± + APScheduler ì‹œì‘"""
    await init_db()

    # APScheduler ì‹œì‘ (ì •ê¸° í¬ë¡¤ë§)
    try:
        from services.scheduler import start_scheduler, stop_scheduler
        start_scheduler()
        logger.info("ğŸ• APScheduler ì •ê¸° í¬ë¡¤ë§ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ë¨")
    except ImportError:
        logger.warning("âš ï¸ APScheduler ë¯¸ì„¤ì¹˜ â€” ì •ê¸° í¬ë¡¤ë§ ë¹„í™œì„±í™” (pip install apscheduler)")
    except Exception as e:
        logger.warning(f"âš ï¸ APScheduler ì‹œì‘ ì‹¤íŒ¨: {e}")

    yield

    # APScheduler ì¢…ë£Œ
    try:
        from services.scheduler import stop_scheduler
        stop_scheduler()
    except Exception:
        pass


# ===== FastAPI App =====

app = FastAPI(
    title=settings.APP_NAME,
    version=settings.APP_VERSION,
    description="IT ìê²©ì¦ í†µí•© ê´€ë¦¬ API - ìê²©ì¦ ì •ë³´ ì¡°íšŒ, ì‹œí—˜ ì¼ì • ê´€ë¦¬, ê²€ìƒ‰/í•„í„°ë§",
    lifespan=lifespan,
)

# ===== CORS ì„¤ì • (Next.js í”„ë¡ íŠ¸ì—”ë“œ í—ˆìš©) =====

app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        settings.FRONTEND_URL,
        "http://localhost:3000",
        "http://127.0.0.1:3000",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ===== ë¼ìš°í„° ë“±ë¡ =====

app.include_router(certifications.router)
app.include_router(schedules.router)
app.include_router(crawl_router)


# ===== í—¬ìŠ¤ì²´í¬ & í†µê³„ =====

@app.get("/api/health")
async def health_check():
    return {"status": "ok", "service": settings.APP_NAME}


@app.get("/api/stats")
async def get_stats():
    """í†µê³„ ì •ë³´ (í”„ë¡ íŠ¸ì—”ë“œ íˆì–´ë¡œ ì„¹ì…˜ìš©)"""
    from sqlalchemy import select, func
    from database import async_session
    from models import Certification, ExamSchedule

    async with async_session() as db:
        total = await db.execute(select(func.count(Certification.id)))
        tags = await db.execute(
            select(func.count(func.distinct(Certification.tag)))
        )
        schedules = await db.execute(select(func.count(ExamSchedule.id)))

    return {
        "total_certs": total.scalar() or 0,
        "total_tags": tags.scalar() or 0,
        "total_schedules": schedules.scalar() or 0,
        "total_levels": 4,
    }


# ===== í¬ë¡¤ëŸ¬ ìˆ˜ë™ ì‹¤í–‰ ì—”ë“œí¬ì¸íŠ¸ (ë ˆê±°ì‹œ í˜¸í™˜ â€” ìƒˆ API: /api/crawl/trigger) =====

@app.post("/api/crawl-legacy")
async def trigger_crawl_legacy(source: str = "all"):
    """
    (ë ˆê±°ì‹œ) í¬ë¡¤ëŸ¬ ìˆ˜ë™ ì‹¤í–‰ â€” ìƒˆ APIë¡œ /api/crawl/trigger ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
    ìƒˆ APIëŠ” CrawlLog ê¸°ë¡ + seed-events.ts ìë™ ë™ê¸°í™”ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
    """
    from services.scheduler import run_crawl_job
    results = await run_crawl_job(source)
    return {
        "status": "completed",
        "strategy": "3-tier fallback (API â†’ Scraping â†’ Cache) + CrawlLog + seed-sync",
        "sources": [r["source"] for r in results],
        "results": results,
    }


# ===== ì‹¤í–‰ =====

if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=settings.DEBUG,
    )
